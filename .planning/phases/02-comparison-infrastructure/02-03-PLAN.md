---
phase: 02-comparison-infrastructure
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - .planning/scripts/compare-html.ts
  - .planning/comparisons/html-reports/
autonomous: true

must_haves:
  truths:
    - "HTML content verification runs against local Nuxt server"
    - "Report lists missing semantic elements (h1-h6, nav, main, footer)"
    - "Report checks for expected text content (company name, key phrases)"
    - "Textual report saved to file for review"
  artifacts:
    - path: ".planning/scripts/compare-html.ts"
      provides: "HTML content verification script"
      min_lines: 80
    - path: ".planning/comparisons/html-reports/YYYY-MM-DD_HH-mm-ss-report.txt"
      provides: "Textual HTML comparison report"
      contains: ["MISSING", "OK", "Content Verification"]
    - path: ".planning/comparisons/html-reports/YYYY-MM-DD_HH-mm-ss-report.json"
      provides: "Structured JSON report for programmatic access"
      contains: ["findings", "page", "timestamp"]
  key_links:
    - from: ".planning/scripts/compare-html.ts"
      to: "http://localhost:3000"
      via: "Playwright fetches HTML from local Nuxt server"
      pattern: "localhost:3000"
    - from: ".planning/scripts/compare-html.ts"
      to: ".planning/audit/pages.json"
      via: "Reads page list for comparison"
      pattern: "pages\\.json"
    - from: ".planning/scripts/compare-html.ts"
      to: "cheerio"
      via: "CSS selector-based content verification"
      pattern: "cheerio.*load"
---

<objective>
Create HTML source content verification that checks semantic elements and key text content exist in the new implementation.

Purpose: Verify content integrity independent of visual appearance. This ensures semantic HTML structure exists even when the design is intentionally different from the old site.

Output: Executable script that generates textual and JSON reports of HTML content findings.
</objective>

<execution_context>
@/home/deck/.claude/get-shit-done/workflows/execute-plan.md
@/home/deck/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-comparison-infrastructure/02-CONTEXT.md
@.planning/phases/02-comparison-infrastructure/02-RESEARCH.md
@.planning/audit/pages.json

# Cheerio already installed from Phase 01
@.planning/phases/01-audit-baseline-capture/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create HTML content verification script</name>
  <files>.planning/scripts/compare-html.ts</files>
  <action>
    Create .planning/scripts/compare-html.ts that:

    1. Reads .planning/audit/pages.json for page list
    2. Starts local Nuxt dev server on port 3000 if not running
    3. Uses Playwright to fetch HTML from each page on localhost:3000
    4. For each page, uses Cheerio to verify:

       **Semantic Elements (from REQ-CMP-002):**
       - h1 (should be exactly 1 per page)
       - h2-h6 (count and report)
       - nav element (header navigation)
       - main element (main content area)
       - footer element
       - article element (if applicable)

       **Content Verification:**
       - Company name: "VP Associates" or "VPAssociates" in body
       - Page title from pages.json matches h1 text (fuzzy match allowed)
       - Contact information presence (phone, email, or address)

    5. Generates findings array with:
       - Page slug
       - Element status (OK/MISSING)
       - Text content matches (OK/MISSING)
       - Specific issues found

    6. Outputs TWO reports:
       - TXT: Human-readable textual report at .planning/comparisons/html-reports/{timestamp}-report.txt
       - JSON: Structured data at .planning/comparisons/html-reports/{timestamp}-report.json

    7. Console output shows summary:
       - Pages checked
       - Total findings
       - Critical issues (missing h1, missing main)

    Use Cheerio selectors (not client-side execution) since we're verifying server-rendered HTML.

    NOTE: Per CONTEXT.md, this is NOT about matching old site HTML structure. We're verifying CONTENT EXISTS, not structure parity.
  </action>
  <verify>test -f .planning/scripts/compare-html.ts && grep -q "cheerio" .planning/scripts/compare-html.ts</verify>
  <done>Script exists with Cheerio-based HTML verification</done>
</task>

<task type="auto">
  <name>Task 2: Run HTML comparison and generate reports</name>
  <files>.planning/comparisons/html-reports/</files>
  <action>
    Execute the HTML comparison:
    1. Ensure Nuxt dev server is running (start if needed: npm run dev &)
    2. Wait for server to be ready
    3. Run: npx tsx .planning/scripts/compare-html.ts
    4. Verify reports generated in .planning/comparisons/html-reports/
    5. Check that both .txt and .json reports exist
    6. Display the textual report summary to console

    Expected output: Reports will show missing content since new implementation is not complete. This is expected - we're building the verification tool, not expecting full content parity yet.
  </action>
  <verify>test -d .planning/comparisons/html-reports && ls .planning/comparisons/html-reports/*.txt && ls .planning/comparisons/html-reports/*.json</verify>
  <done>HTML reports generated with content verification findings</done>
</task>

<task type="auto">
  <name>Task 3: Create report documentation</name>
  <files>.planning/comparisons/html-reports/README.md</files>
  <action>
    Create .planning/comparisons/html-reports/README.md documenting:

    1. Report purpose: Content verification, not structural matching
    2. Report format: Both TXT (human) and JSON (programmatic)
    3. How to run comparison: npx tsx .planning/scripts/compare-html.ts
    4. Understanding findings:
       - MISSING: Expected content not found
       - OK: Content verified present
       - What elements are checked (h1, nav, main, footer, etc.)
    5. Report naming convention: timestamp-report.{txt,json}
    6. How to use findings for fixing content issues

    Keep documentation concise (100-150 lines).
  </action>
  <verify>test -f .planning/comparisons/html-reports/README.md</verify>
  <done>README documents HTML comparison process and report format</done>
</task>

</tasks>

<verification>
After completion, verify:
- [ ] compare-html.ts script exists and uses Cheerio
- [ ] Script checks semantic elements (h1, nav, main, footer)
- [ ] Script verifies text content (company name, titles)
- [ ] Both .txt and .json reports generated
- [ ] Reports saved to timestamped directory
- [ ] README.md documents the process
- [ ] Script is idempotent - can be re-run
</verification>

<success_criteria>
1. Running `npx tsx .planning/scripts/compare-html.ts` produces timestamped reports
2. Reports list semantic element findings (OK/MISSING)
3. Reports verify text content presence
4. README explains how to interpret and use the findings
</success_criteria>

<output>
After completion, create `.planning/phases/02-comparison-infrastructure/02-03-SUMMARY.md`

Include in SUMMARY:
- Number of pages checked
- Total findings count
- Critical issues found (missing h1, main, etc.)
- Report location
</output>
