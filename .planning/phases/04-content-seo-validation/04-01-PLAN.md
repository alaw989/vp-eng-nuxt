---
phase: 04-content-seo-validation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - .planning/audit/broken-links.json
  - .planning/scripts/validate-links.ts
autonomous: true

must_haves:
  truths:
    - "All internal links from source pages extracted and validated"
    - "HTTP status codes recorded for each link (200, 301, 404, etc.)"
    - "Broken links categorized by severity (critical, warning, info)"
    - "Report generated as structured JSON for analysis"
    - "External links documented separately for reference"
  artifacts:
    - path: ".planning/audit/broken-links.json"
      provides: "Complete link validation report with severity categorization"
      contains: "[{\"url\",\"status\",\"source\",\"severity\""
    - path: ".planning/scripts/validate-links.ts"
      provides: "Reusable link validation script for future audits"
      contains: "export async function validateLinks"
  key_links:
    - from: ".planning/audit/broken-links.json"
      to: ".planning/audit/pages.json"
      via: "Uses page URLs as starting points for link extraction"
      pattern: "pages.json"
    - from: ".planning/scripts/validate-links.ts"
      to: "04-02-PLAN.md"
      via: "Link validation needed before content comparison can run"
      pattern: "validate-links.ts"
---

<objective>
Create and execute an internal link validation script that crawls all pages from the source WordPress site (vp-associates.com), extracts internal links, checks their HTTP status codes, and generates a categorized broken link report.

Purpose: Identify broken internal links before launch. Broken links indicate migration failure and hurt SEO rankings. The report provides actionable data for fixing navigation issues.

Output: Broken link report at `.planning/audit/broken-links.json` with severity categorization (critical=404, warning=redirect, info=external)
</objective>

<execution_context>
@/home/deck/.claude/get-shit-done/workflows/execute-plan.md
@/home/deck/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-content-seo-validation/04-RESEARCH.md
@.planning/audit/pages.json
</context>

<tasks>

<task type="auto">
  <name>Install Cheerio for HTML parsing</name>
  <files>package.json, package-lock.json</files>
  <action>
    Install Cheerio as a development dependency for HTML parsing and link extraction:

    ```bash
    npm install --save-dev cheerio
    npm install --save-dev @types/cheerio
    ```

    Cheerio provides jQuery-like selector syntax for parsing HTML and extracting links. It's the standard library for this task in Node.js.
  </action>
  <verify>`grep -E '"cheerio|"@types/cheerio' package.json` returns both packages</verify>
  <done>Cheerio installed and available for import</done>
</task>

<task type="auto">
  <name>Create link validation script</name>
  <files>.planning/scripts/validate-links.ts</files>
  <action>
    Create TypeScript script at `.planning/scripts/validate-links.ts` with the following structure:

    **Imports:**
    ```typescript
    import { ofetch } from 'ofetch'
    import * as cheerio from 'cheerio'
    import { readFileSync, writeFileSync } from 'fs'
    import { join } from 'path'
    ```

    **Interfaces:**
    ```typescript
    interface PageEntry {
      url: string
      slug: string
      type: string
      title?: string
    }

    interface LinkCheckResult {
      url: string
      status: number
      statusText: string
      ok: boolean
      sourcePage: string
      linkText?: string
      severity: 'critical' | 'warning' | 'info' | 'success'
    }

    interface BrokenLinkReport {
      generated: string
      source: string
      pagesChecked: number
      linksChecked: number
      summary: {
        critical: number      // 404s, 500s
        warning: number       // 301, 302 redirects
        info: number          // external links
        success: number       // 200 OK
      }
      links: LinkCheckResult[]
    }
    ```

    **Functions to implement:**

    1. `function isInternalLink(url: string, baseUrl: URL): boolean`
       - Parse URL and check if hostname matches baseUrl.hostname
       - Return true for same-origin links, false for external

    2. `function extractLinks(html: string, sourceUrl: string): Array<{href: string, text: string}>`
       - Load HTML with Cheerio
       - Select all `a[href]` elements
       - Extract href and link text
       - Return array of link objects

    3. `function categorizeStatus(status: number): LinkCheckResult['severity']`
       - 200: 'success'
       - 301, 302, 307, 308: 'warning' (redirects should be reviewed)
       - 404, 410, 500, 502, 503: 'critical' (broken)
       - Other: 'info'

    4. `async function checkLinkStatus(url: string, sourceUrl: string): Promise<LinkCheckResult>`
       - Use ofetch.raw() to get response with status code
       - Configure with `ignoreResponseError: true` to handle 404s gracefully
       - Set timeout to 10000ms
       - Return LinkCheckResult with proper categorization

    5. `async function validatePages(pages: PageEntry[]): Promise<BrokenLinkReport>`
       - For each page in pages array:
         - Fetch page HTML
         - Extract all links
         - Filter to internal links only
         - Check status of each link
         - Track results by severity
       - Build summary statistics
       - Return complete report

    **Main execution:**
    ```typescript
    async function main() {
      // Load pages from audit
      const pagesPath = join(process.cwd(), '.planning', 'audit', 'pages.json')
      const pages: PageEntry[] = JSON.parse(readFileSync(pagesPath, 'utf-8'))

      console.log(`Validating links from ${pages.length} pages...`)

      // Run validation
      const report = await validatePages(pages)

      // Write report
      const reportPath = join(process.cwd(), '.planning', 'audit', 'broken-links.json')
      writeFileSync(reportPath, JSON.stringify(report, null, 2))

      // Log summary
      console.log('\n=== Link Validation Summary ===')
      console.log(`Pages checked: ${report.pagesChecked}`)
      console.log(`Links checked: ${report.linksChecked}`)
      console.log(`\nResults:`)
      console.log(`  Success (200): ${report.summary.success}`)
      console.log(`  Warnings (3xx): ${report.summary.warning}`)
      console.log(`  Critical (4xx/5xx): ${report.summary.critical}`)
      console.log(`  External: ${report.summary.info}`)

      if (report.summary.critical > 0) {
        console.log(`\n⚠️ Found ${report.summary.critical} broken links!`)
      }
    }

    main().catch(console.error)
    ```

    **Important:**
    - Use relative paths for file operations
    - Handle network errors gracefully (status 0 = network error)
    - Deduplicate links by URL before checking (avoid redundant requests)
    - Include proper error handling for Cheerio parsing
  </action>
  <verify>Script file exists at `.planning/scripts/validate-links.ts` with all required functions</verify>
  <done>Link validation script created with complete implementation</done>
</task>

<task type="auto">
  <name>Execute link validation</name>
  <files>.planning/audit/broken-links.json</files>
  <action>
    Run the link validation script:

    ```bash
    npx tsx .planning/scripts/validate-links.ts
    ```

    The script will:
    1. Load pages from `.planning/audit/pages.json`
    2. Fetch each page and extract internal links
    3. Check HTTP status for each link
    4. Generate categorized report

    Expected runtime: 1-3 minutes depending on network speed and number of links.

    After completion, verify the report:
    ```bash
    cat .planning/audit/broken-links.json | jq '.summary'
    ```
  </action>
  <verify>`.planning/audit/broken-links.json` exists and contains valid JSON with summary and links array</verify>
  <done>Link validation complete with categorized report generated</done>
</task>

<task type="auto">
  <name>Review and document broken links</name>
  <files>.planning/phases/04-content-seo-validation/04-01-SUMMARY.md</files>
  <action>
    Review the generated broken link report:

    ```bash
    # View critical links
    cat .planning/audit/broken-links.json | jq '.links[] | select(.severity == "critical")'

    # View warnings (redirects)
    cat .planning/audit/broken-links.json | jq '.links[] | select(.severity == "warning")'
    ```

    Document findings:
    1. Count of critical broken links (404s)
    2. Count of redirect warnings (3xx)
    3. Any patterns in broken links (e.g., all from same section)
    4. External link count for reference

    This data will inform:
    - 04-04: URL structure documentation and redirect implementation
    - 04-05: Sitemap generation (exclude broken URLs)

    Create notes in the task commit about what was found.
  </action>
  <verify>Able to query and interpret broken link report data</verify>
  <done>Broken links documented and understood for follow-up plans</done>
</task>

</tasks>

<verification>
After completion, verify:
1. `.planning/scripts/validate-links.ts` exists with complete implementation
2. `.planning/audit/broken-links.json` exists and contains valid JSON
3. Report includes: generated timestamp, pagesChecked count, linksChecked count
4. Summary has counts for: critical, warning, info, success
5. Links array includes: url, status, sourcePage, severity for each link
6. Script can be re-run for future validation
7. No network errors (all links checked successfully)
</verification>

<success_criteria>
1. Link validation script created and executes successfully
2. Broken link report generated with complete data
3. All severity categories properly populated
4. Critical broken links identified and documented
5. Redirect warnings flagged for review
6. External links counted separately
7. REQ-LNK-001 acceptance criteria met:
   - All internal links extracted from pages.json
   - HTTP status checked for each link
   - Broken link report generated
   - Links categorized by severity
</success_criteria>

<output>
After completion, create `.planning/phases/04-content-seo-validation/04-01-SUMMARY.md` with:
- Total pages checked
- Total links validated
- Count of broken links by severity
- Any patterns observed in broken links
- Confirmation of REQ-LNK-001 completion
- Next steps recommendation (proceed to 04-02 content integrity comparison)
</output>
